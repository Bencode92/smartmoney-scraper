# SmartMoney Scraper ğŸš€

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://img.shields.io/badge/tests-passing-green.svg)](tests/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

ğŸ“Š **Scraper Python robuste et intelligent pour donnÃ©es hedge funds et superinvestors**

## ğŸ¯ Objectif

SystÃ¨me de scraping professionnel avec anti-dÃ©tection pour rÃ©cupÃ©rer et consolider les donnÃ©es de :
- **HedgeFollow** : Top hedge funds, holdings, insider trading, stock screener
- **Dataroma** : Superinvestors, holdings, Grand Portfolio, Real-time insiders

## âœ¨ FonctionnalitÃ©s

### ğŸ›¡ï¸ Robustesse
- âœ… **Validation des donnÃ©es** : VÃ©rification automatique de la cohÃ©rence
- âœ… **Anti-dÃ©tection** : Rotation de User-Agents et headers intelligents
- âœ… **Monitoring** : MÃ©triques en temps rÃ©el et alertes
- âœ… **Tests automatisÃ©s** : Suite de tests complÃ¨te
- âœ… **Gestion d'erreurs** : Retry intelligent avec backoff exponentiel

### ğŸ“ˆ Performance
- ğŸš€ Cache intelligent avec rafraÃ®chissement automatique
- ğŸ“Š MÃ©triques de qualitÃ© des donnÃ©es
- ğŸ”„ Pipeline CI/CD via GitHub Actions
- ğŸ’¾ Support CSV et formats optimisÃ©s

## ğŸ“¦ Installation

```bash
git clone https://github.com/Bencode92/smartmoney-scraper.git
cd smartmoney-scraper
pip install -r requirements.txt
cp .env.example .env
```

## ğŸš€ Usage

### Utilisation Simple

```python
from src.hedgefollow.funds import get_top_n_funds

# RÃ©cupÃ©rer les top 10 hedge funds
funds = get_top_n_funds(
    n=10,
    min_aum=1_000_000_000,  # Minimum 1B$ AUM
    min_perf_3y=10.0         # Minimum 10% perf 3 ans
)
print(funds[['name', 'aum_usd', 'perf_3y']])
```

### Pipeline Complet

```bash
# Mise Ã  jour complÃ¨te avec monitoring
python -m src.hedgefollow.funds

# Ou via les scripts
./scripts/run_pipeline.sh
```

### Tests de Validation

```bash
# Lancer tous les tests
pytest tests/ -v

# Test spÃ©cifique avec coverage
pytest tests/test_hedgefollow_scraper.py -v --cov=src
```

## ğŸ“Š Architecture AmÃ©liorÃ©e

```
src/
â”œâ”€â”€ config.py           # Configuration globale
â”œâ”€â”€ validators.py       # ğŸ†• Validation robuste des donnÃ©es
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ http.py        # ğŸ”¥ Anti-dÃ©tection avancÃ©e
â”‚   â”œâ”€â”€ monitoring.py  # ğŸ†• MÃ©triques et alertes
â”‚   â”œâ”€â”€ parsing.py     # Parsing HTML normalisÃ©
â”‚   â””â”€â”€ io.py          # I/O optimisÃ©
â”œâ”€â”€ hedgefollow/       # Scrapers HedgeFollow
â”œâ”€â”€ dataroma/          # Scrapers Dataroma
â””â”€â”€ pipelines/         # Consolidation intelligente

tests/
â””â”€â”€ test_hedgefollow_scraper.py  # ğŸ†• Tests complets
```

## ğŸ›¡ï¸ FonctionnalitÃ©s de SÃ©curitÃ©

### Anti-DÃ©tection
- **Rotation User-Agent** : 12+ navigateurs diffÃ©rents
- **Headers dynamiques** : Accept-Language, Referer variÃ©s
- **Throttling intelligent** : DÃ©lais alÃ©atoires et adaptatifs
- **Support proxy** : Rotation de proxies (optionnel)

### Validation des DonnÃ©es
```python
from src.validators import DataValidator

# Validation automatique
DataValidator.validate_funds(df, min_funds=5)
DataValidator.check_data_freshness(df, max_days=7)
```

### Monitoring en Temps RÃ©el
```python
from src.utils.monitoring import track_performance, alerts

@track_performance("my_function")
def scrape_data():
    # Votre code
    pass

# Alertes automatiques
alerts.send_alert(
    "Scraping Ã©chouÃ©",
    "Erreur critique dÃ©tectÃ©e",
    level="CRITICAL"
)
```

## ğŸ“ˆ MÃ©triques et KPIs

Le systÃ¨me track automatiquement :
- â±ï¸ Temps d'exÃ©cution par module
- ğŸ“Š Taux de remplissage des colonnes
- âš ï¸ DÃ©tection d'anomalies (outliers)
- âŒ Taux d'erreur et retry
- ğŸ“‰ Volume de donnÃ©es scrapÃ©es

## ğŸ”§ Configuration AvancÃ©e

### Variables d'Environnement

```bash
# API Keys (enrichissement futur)
TWELVE_DATA_API_KEY=your_key_here

# HTTP Settings
HTTP_USER_AGENT="Mozilla/5.0..."  # Optionnel, rotation auto
REQUESTS_SLEEP_SECONDS=2           # DÃ©lai entre requÃªtes

# Scraping Parameters
HEDGEFOLLOW_TOP_N_FUNDS=15
DATAROMA_TOP_N_MANAGERS=10
INSIDER_MIN_VALUE_USD=5000000

# Alerting (optionnel)
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/...
```

## ğŸ§ª Tests et Validation

### Structure des Tests

```python
# Tests unitaires
test_validate_funds_success()      # Validation rÃ©ussie
test_validate_funds_missing_data() # Gestion donnÃ©es manquantes
test_scraping_with_fallback()      # StratÃ©gies de fallback

# Tests d'intÃ©gration
test_full_pipeline()                # Pipeline complet
test_network_resilience()           # RÃ©silience rÃ©seau
```

### Lancer les Tests

```bash
# Tests rapides
pytest tests/ -v -m "not integration"

# Tests complets avec rapport
pytest tests/ -v --cov=src --cov-report=html
```

## ğŸ“Š DonnÃ©es GÃ©nÃ©rÃ©es

### Structure des DonnÃ©es

```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ hedgefollow/
â”‚   â”‚   â”œâ”€â”€ funds_top.csv          # Top hedge funds
â”‚   â”‚   â”œâ”€â”€ holdings_20241124.csv  # Positions dÃ©taillÃ©es
â”‚   â”‚   â””â”€â”€ insiders_20241124.csv  # Trades insiders
â”‚   â””â”€â”€ dataroma/
â”‚       â”œâ”€â”€ managers.csv           # Superinvestors
â”‚       â””â”€â”€ holdings_20241124.csv  # Positions
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ universe_smartmoney_20241124.csv  # ConsolidÃ©
â””â”€â”€ metrics.jsonl                  # ğŸ†• MÃ©triques de monitoring
```

### Format des DonnÃ©es

| Colonne | Type | Description |
|---------|------|-------------|
| fund_id | str | Identifiant unique |
| name | str | Nom du fond |
| aum_usd | float | Assets Under Management |
| perf_3y | float | Performance 3 ans (%) |
| num_holdings | int | Nombre de positions |
| scraped_at | datetime | Timestamp du scraping |

## ğŸš€ CI/CD avec GitHub Actions

### Workflows AutomatisÃ©s

- **Daily Scraping** : Mise Ã  jour quotidienne Ã  6h UTC
- **Weekly Full** : Scraping complet hebdomadaire
- **On Push** : Tests automatiques sur chaque commit

## ğŸ“ˆ Monitoring et Alertes

### Dashboard de SantÃ©

```python
from src.utils.monitoring import check_scraping_health

health = check_scraping_health()
print(f"Status: {health['status']}")
# Output: Status: HEALTHY âœ…
```

### Webhook Discord/Slack

Configuration automatique des alertes critiques via webhooks.

## ğŸ”„ Prochaines Ã‰tapes

- [x] Validation robuste des donnÃ©es
- [x] Anti-dÃ©tection avancÃ©e
- [x] Monitoring et mÃ©triques
- [x] Tests automatisÃ©s
- [ ] Enrichissement Twelve Data API
- [ ] Support Parquet/SQLite
- [ ] Dashboard Streamlit
- [ ] ML pour dÃ©tection de patterns

## ğŸ¤ Contribution

Les contributions sont bienvenues ! Voir [CONTRIBUTING.md](CONTRIBUTING.md)

## ğŸ“œ License

MIT - Voir [LICENSE](LICENSE)

## âš ï¸ Disclaimer

Ce projet est Ã  des fins Ã©ducatives. Respectez les conditions d'utilisation des sites scrapÃ©s et les limites de rate.

---

**DÃ©veloppÃ© avec â¤ï¸ par [Bencode92](https://github.com/Bencode92)**
